{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import *\n",
    "from models import *\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from Bio.SeqUtils import GC\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JUND cofactors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cofactors - MCC:\n",
    "* SP1      0.349809\n",
    "* MAFG     0.307209\n",
    "* MAFF     0.268983\n",
    "* NFIC     0.253942\n",
    "* CEBPB    0.245328"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JUND multi-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspecting both - cofactors and random tfs\n",
    "#data = h5py.File(\"../for_Manu/TRAIN_DATA_COFACTORS_SUBSAMPLE_I_False/JUND_multi_1/h5_files/tf_peaks_JUND.h5\", 'r')\n",
    "data = h5py.File(\"../for_Manu/TRAIN_DATA_RANDOM_SUBSAMPLE_I_False/JUND_multi_1/h5_files/tf_peaks_JUND.h5\", 'r')\n",
    "\n",
    "x = torch.Tensor(data['train_in'])\n",
    "y = torch.Tensor(data['valid_in'])\n",
    "z = torch.Tensor(data['test_in'])\n",
    "\n",
    "x_lab = torch.Tensor(data['train_out'])\n",
    "y_lab = torch.Tensor(data['valid_out'])\n",
    "z_lab = torch.Tensor(data['test_out'])\n",
    "\n",
    "res = torch.cat((x, y, z), dim=0)\n",
    "res_lab = torch.cat((x_lab, y_lab, z_lab), dim=0)\n",
    "\n",
    "all_dataset = torch.utils.data.TensorDataset(res, res_lab)\n",
    "dataloader = torch.utils.data.DataLoader(all_dataset, \n",
    "                                                  batch_size=100, shuffle=False,\n",
    "                                                  num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNetDeep(5).to(device)\n",
    "\n",
    "#model.load_state_dict(torch.load(\"../for_Manu/MODEL_WEIGHTS_COFACTORS_SUBSAMPLE_I_False/JUND_real_multimodel_weights_1/model_epoch_4_.pth\"))\n",
    "model.load_state_dict(torch.load(\"../for_Manu/MODEL_WEIGHTS_RANDOM_SUBSAMPLE_I_False/JUND_real_multimodel_weights_1/model_epoch_4_.pth\"))\n",
    "model.eval();\n",
    "\n",
    "#copy trained model weights to motif extraction model\n",
    "motif_model = motifCNN(model, 5).to(device)\n",
    "motif_model.load_state_dict(model.state_dict())\n",
    "motif_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run predictions with full model on all data\n",
    "running_outputs = []\n",
    "running_labels = []\n",
    "sequences = []\n",
    "sigmoid = nn.Sigmoid()\n",
    "with torch.no_grad():\n",
    "    for seq, lbl in dataloader:\n",
    "        sequences.extend(seq.numpy())\n",
    "        seq = seq.to(device)\n",
    "        out = model(seq)\n",
    "        out = sigmoid(out.detach().cpu()) #for BCEWithLogits\n",
    "        running_outputs.extend(out.numpy()) #for BCEWithLogits\n",
    "        running_labels.extend(lbl.numpy())\n",
    "\n",
    "running_labels = np.array(running_labels)\n",
    "running_outputs = np.array(running_outputs)\n",
    "sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_full_round = np.round(running_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_comp = np.equal(pred_full_round, running_labels)\n",
    "idx = np.argwhere(np.sum(arr_comp, axis=1) >= 5).squeeze() #43563"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_idx = np.random.choice(idx, size=80000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = res[sampled_idx, :, :]\n",
    "res_lab2 = res_lab[sampled_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.TensorDataset(res2, res_lab2)\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                          batch_size=100, shuffle=False,\n",
    "                                                  num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, activations = get_motifs(data_loader, motif_model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_file_path = \"../for_Manu/motifs/motifs_for_JUND_multimodel.meme\"\n",
    "output_file_path = \"../for_Manu/motifs/motifs_for_JUND_random_multimodel.meme\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_memes(activations, res2, res_lab2, output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JUND individual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = h5py.File(\"../for_Manu/TRAIN_DATA_COFACTORS_SUBSAMPLE_I_False/JUND_indiv_1/h5_files/JUND_tl.h5\", 'r')\n",
    "data = h5py.File(\"../for_Manu/TRAIN_DATA_RANDOM_SUBSAMPLE_I_False/JUND_indiv_1/h5_files/JUND_tl.h5\", 'r')\n",
    "\n",
    "x = torch.Tensor(data['train_in'])\n",
    "y = torch.Tensor(data['valid_in'])\n",
    "z = torch.Tensor(data['test_in'])\n",
    "\n",
    "x_lab = torch.Tensor(data['train_out'])\n",
    "y_lab = torch.Tensor(data['valid_out'])\n",
    "z_lab = torch.Tensor(data['test_out'])\n",
    "\n",
    "res = torch.cat((x, y, z), dim=0)\n",
    "res_lab = torch.cat((x_lab, y_lab, z_lab), dim=0)\n",
    "\n",
    "all_dataset = torch.utils.data.TensorDataset(res, res_lab)\n",
    "dataloader = torch.utils.data.DataLoader(all_dataset, \n",
    "                                                  batch_size=100, shuffle=False,\n",
    "                                                  num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNetDeep(1).to(device)\n",
    "\n",
    "#model.load_state_dict(torch.load(\"../for_Manu/MODEL_WEIGHTS_COFACTORS_SUBSAMPLE_I_False/JUND_real_indiv_weights_1/JUND_tl_weights/model_epoch_2_.pth\"))\n",
    "model.load_state_dict(torch.load(\"../for_Manu/MODEL_WEIGHTS_RANDOM_SUBSAMPLE_I_False/JUND_real_indiv_weights_1/JUND_tl_weights/model_epoch_3_.pth\"))\n",
    "model.eval();\n",
    "\n",
    "#copy trained model weights to motif extraction model\n",
    "motif_model = motifCNN(model, 1).to(device)\n",
    "motif_model.load_state_dict(model.state_dict())\n",
    "motif_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run predictions with full model on all data\n",
    "running_outputs = []\n",
    "running_labels = []\n",
    "sequences = []\n",
    "sigmoid = nn.Sigmoid()\n",
    "with torch.no_grad():\n",
    "    for seq, lbl in dataloader:\n",
    "        sequences.extend(seq.numpy())\n",
    "        seq = seq.to(device)\n",
    "        out = model(seq)\n",
    "        out = sigmoid(out.detach().cpu()) #for BCEWithLogits\n",
    "        running_outputs.extend(out.numpy()) #for BCEWithLogits\n",
    "        running_labels.extend(lbl.numpy())\n",
    "\n",
    "running_labels = np.array(running_labels)\n",
    "running_outputs = np.array(running_outputs)\n",
    "sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_full_round = np.round(running_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_comp = np.equal(pred_full_round, running_labels)\n",
    "idx = np.argwhere(np.sum(arr_comp, axis=1) >= 1).squeeze() #43563\n",
    "\n",
    "res2 = res[idx, :, :]\n",
    "res_lab2 = res_lab[idx, :]\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(res2, res_lab2)\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                          batch_size=100, shuffle=False,\n",
    "                                                  num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, activations = get_motifs(data_loader, motif_model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = \"../for_Manu/motifs/motifs_for_JUND_random_individual.meme\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_memes(activations, res2, res_lab2, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results for multimodel_cofactors (q.value 0.01)\n",
    "multi_cofactors = {'filter11':'JUND', 'filter30':'MAFG/MAFF', 'filter5':'SP1',\n",
    "                  'filter72':'Fos:Jun', 'filter75':'CEBPB', 'filter64':'CTCF',\n",
    "                  'filter40':'CEBPB', 'filter8':'MAFG', 'filter37':'MAFG/MAFF',\n",
    "                  'filter19':'MAFG/MAFF','filter80':'MAFG/MAFF','filter94':'JUND',\n",
    "                  'filter60':'NRL', 'filter43':'Gmeb1'}\n",
    "\n",
    "indiv_cofactors = {'filter11':'JUND', 'filter30':'MAFG/MAFF', 'filter72':'Fos:Jun',\n",
    "                  'filter5':'SP1','filter8':'Fos:JUN', 'filter94':'JUND', 'filter40':'CEBPB',\n",
    "                  'filter37':'Fos:JUN', 'filter76':'JUND', 'filter90':'JUND',\n",
    "                  'filter52':'JUND', 'filter36':'MAFG', 'filter39':'JUND',\n",
    "                  'filter43':'NRL', 'filter93':'JUND', 'filter27':'JUND', 'filter1':'JUND',\n",
    "                  'filter60':'NRL', 'filter50':'JUND', 'filter73':'JUND', 'filter63':'JUND',\n",
    "                  'filter19':'MAFG', 'filter82':'JUND', 'filter18':'MAFG'}\n",
    "\n",
    "#['ZNF143', 'TP63', 'GATA3', 'ELK1', 'RXRA']\n",
    "multi_random = {'filter17':'RXRA', 'filter87':'TP73', 'filter96':'ELF5', 'filter68':'CTCF',\n",
    "               'filter74':'NRL', 'filter41':'CTCF', 'filter44':'CTCF', \n",
    "                'filter43':'TP73', 'filter88':'CTCF', 'filter99':'TP73', 'filter':'HOXD3',\n",
    "               'filter42':'TP73', 'filter66':'CTCF', 'filter91':'Rhox11',\n",
    "               'filter89':'Gmeb1'}\n",
    "\n",
    "indiv_random = {'filter85':'JUND', 'filter74':'NRL', 'filter87':'TP73',\n",
    "               'filter75':'HOXD3', 'filter30':'JUND', 'filter96':'ELF5',\n",
    "               'filter39':'Gmeb1', 'filter89':'Gmeb1', 'filter91':\"Rhox11\",\n",
    "               'filter43':'TP73'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HNF4A cofactors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cofactors - MCC\n",
    "* NR2F2    0.253237\n",
    "* FOXA2    0.238407\n",
    "* FOXA1    0.235406\n",
    "* SP1      0.212225\n",
    "* MYBL2    0.197924"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HNF4A multi-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = h5py.File(\"../for_Manu/TRAIN_DATA_COFACTORS_SUBSAMPLE_I_False/HNF4A_multi_1/h5_files/tf_peaks_HNF4A.h5\", 'r')\n",
    "data = h5py.File(\"../for_Manu/TRAIN_DATA_RANDOM_SUBSAMPLE_I_False/HNF4A_multi_1/h5_files/tf_peaks_HNF4A.h5\", 'r')\n",
    "\n",
    "x = torch.Tensor(data['train_in'])\n",
    "y = torch.Tensor(data['valid_in'])\n",
    "z = torch.Tensor(data['test_in'])\n",
    "\n",
    "x_lab = torch.Tensor(data['train_out'])\n",
    "y_lab = torch.Tensor(data['valid_out'])\n",
    "z_lab = torch.Tensor(data['test_out'])\n",
    "\n",
    "res = torch.cat((x, y, z), dim=0)\n",
    "res_lab = torch.cat((x_lab, y_lab, z_lab), dim=0)\n",
    "\n",
    "all_dataset = torch.utils.data.TensorDataset(res, res_lab)\n",
    "dataloader = torch.utils.data.DataLoader(all_dataset, \n",
    "                                                  batch_size=100, shuffle=False,\n",
    "                                                  num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNetDeep(5).to(device)\n",
    "\n",
    "#model.load_state_dict(torch.load(\"../for_Manu/MODEL_WEIGHTS_COFACTORS_SUBSAMPLE_I_False/HNF4A_real_multimodel_weights_1/model_epoch_4_.pth\"))\n",
    "model.load_state_dict(torch.load(\"../for_Manu/MODEL_WEIGHTS_RANDOM_SUBSAMPLE_I_False/HNF4A_real_multimodel_weights_1/model_epoch_4_.pth\"))\n",
    "model.eval();\n",
    "\n",
    "#copy trained model weights to motif extraction model\n",
    "motif_model = motifCNN(model, 5).to(device)\n",
    "motif_model.load_state_dict(model.state_dict())\n",
    "motif_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run predictions with full model on all data\n",
    "running_outputs = []\n",
    "running_labels = []\n",
    "sequences = []\n",
    "sigmoid = nn.Sigmoid()\n",
    "with torch.no_grad():\n",
    "    for seq, lbl in dataloader:\n",
    "        sequences.extend(seq.numpy())\n",
    "        seq = seq.to(device)\n",
    "        out = model(seq)\n",
    "        out = sigmoid(out.detach().cpu()) #for BCEWithLogits\n",
    "        running_outputs.extend(out.numpy()) #for BCEWithLogits\n",
    "        running_labels.extend(lbl.numpy())\n",
    "\n",
    "running_labels = np.array(running_labels)\n",
    "running_outputs = np.array(running_outputs)\n",
    "sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_full_round = np.round(running_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_comp = np.equal(pred_full_round, running_labels)\n",
    "idx = np.argwhere(np.sum(arr_comp, axis=1) >= 5).squeeze() #43563"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_idx = np.random.choice(idx, size=80000, replace=False)\n",
    "\n",
    "res2 = res[sampled_idx, :, :]\n",
    "res_lab2 = res_lab[sampled_idx, :]\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(res2, res_lab2)\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                          batch_size=100, shuffle=False,\n",
    "                                                  num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, activations = get_motifs(data_loader, motif_model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_file_path = \"../for_Manu/motifs/motifs_for_HNF4A_multimodel.meme\"\n",
    "output_file_path = \"../for_Manu/motifs/motifs_for_HNF4A_random_multimodel.meme\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_memes(activations, res2, res_lab2, output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HNF4A individual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = h5py.File(\"../for_Manu/TRAIN_DATA_COFACTORS_SUBSAMPLE_I_False/HNF4A_indiv_1/h5_files/HNF4A_tl.h5\", 'r')\n",
    "data = h5py.File(\"../for_Manu/TRAIN_DATA_RANDOM_SUBSAMPLE_I_False/HNF4A_indiv_1/h5_files/HNF4A_tl.h5\", 'r')\n",
    "\n",
    "x = torch.Tensor(data['train_in'])\n",
    "y = torch.Tensor(data['valid_in'])\n",
    "z = torch.Tensor(data['test_in'])\n",
    "\n",
    "x_lab = torch.Tensor(data['train_out'])\n",
    "y_lab = torch.Tensor(data['valid_out'])\n",
    "z_lab = torch.Tensor(data['test_out'])\n",
    "\n",
    "res = torch.cat((x, y, z), dim=0)\n",
    "res_lab = torch.cat((x_lab, y_lab, z_lab), dim=0)\n",
    "\n",
    "all_dataset = torch.utils.data.TensorDataset(res, res_lab)\n",
    "dataloader = torch.utils.data.DataLoader(all_dataset, \n",
    "                                                  batch_size=100, shuffle=False,\n",
    "                                                  num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_labels = list(data['target_labels'])\n",
    "\n",
    "target_labels = [i.decode(\"utf-8\") for i in target_labels]\n",
    "target_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNetDeep(1).to(device)\n",
    "\n",
    "#model.load_state_dict(torch.load(\"../for_Manu/MODEL_WEIGHTS_COFACTORS_SUBSAMPLE_I_False/HNF4A_real_indiv_weights_1/HNF4A_tl_weights/model_epoch_4_.pth\"))\n",
    "model.load_state_dict(torch.load(\"../for_Manu/MODEL_WEIGHTS_RANDOM_SUBSAMPLE_I_False/HNF4A_real_indiv_weights_1/HNF4A_tl_weights/model_epoch_4_.pth\"))\n",
    "model.eval();\n",
    "\n",
    "#copy trained model weights to motif extraction model\n",
    "motif_model = motifCNN(model, 1).to(device)\n",
    "motif_model.load_state_dict(model.state_dict())\n",
    "motif_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run predictions with full model on all data\n",
    "running_outputs = []\n",
    "running_labels = []\n",
    "sequences = []\n",
    "sigmoid = nn.Sigmoid()\n",
    "with torch.no_grad():\n",
    "    for seq, lbl in dataloader:\n",
    "        sequences.extend(seq.numpy())\n",
    "        seq = seq.to(device)\n",
    "        out = model(seq)\n",
    "        out = sigmoid(out.detach().cpu()) #for BCEWithLogits\n",
    "        running_outputs.extend(out.numpy()) #for BCEWithLogits\n",
    "        running_labels.extend(lbl.numpy())\n",
    "\n",
    "running_labels = np.array(running_labels)\n",
    "running_outputs = np.array(running_outputs)\n",
    "sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_full_round = np.round(running_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_comp = np.equal(pred_full_round, running_labels)\n",
    "idx = np.argwhere(np.sum(arr_comp, axis=1) >= 1).squeeze() #43563"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = res[idx, :, :]\n",
    "res_lab2 = res_lab[idx, :]\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(res2, res_lab2)\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                          batch_size=100, shuffle=False,\n",
    "                                                  num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, activations = get_motifs(data_loader, motif_model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_file_path = \"../for_Manu/motifs/motifs_for_HNF4A_individual.meme\"\n",
    "output_file_path = \"../for_Manu/motifs/motifs_for_HNF4A_random_individual.meme\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_memes(activations, res2, res_lab2, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results for multimodel_cofactors (q.value 0.01)\n",
    "#NR2F2 FOXA2 FOXA1 SP1 MYBL2 \n",
    "#NR2F2 and RXRA - 0.24 (RXRA and HNF4A are 0.41), FOXA2/FOXA1 and RXRA - 0.16/0.12\n",
    "#SP1 and RXRA - 0.23, MYBL2 and RXRA - 0.20;\n",
    "\n",
    "#and RXRA and HNFA are the same BM - 13\n",
    "multi_cofactors = {'filter28':'RXRA/HNF4G/NR2C2', 'filter66':\"Gmeb1\", \"filter5\":'FOXA1',\n",
    "                  'filter34':'Gmeb1', 'filter12':\"FOXJ3\", \"filter19\":'Gmeb1',\n",
    "                  \"filter64\":\"Fos:JUN\", \"filter99\":\"FOXA2\", \"filter6\":\"FOXA1\",\n",
    "                  \"filter2\":\"NR2F1\", \"filter92\":\"RXRA/NR4A2/HNF4G\", \"filter40\":\"NR1H4\",\n",
    "                  \"filter96\":\"PPARA:RXRA/HNF4G\", \"filter29\":\"PPARA:RXRA/HNF4G\",\n",
    "                  \"filter62\":\"RARA:RXRG/FOXA1\", \"filter71\":\"MEOX1\", \n",
    "                   \"filter78\":\"Gmeb1\", \"filter54\":\"Gmeb1\", \"filter13\":\"FOXJ3/NR1H3:RXRA\",\n",
    "                  \"filter21\":\"Fos:JUN/CREB1\"}\n",
    "\n",
    "indiv_cofactors = {'filter28':'HNF4G', 'filter96':'HNF4G', 'filter66':'Gmeb1',\n",
    "                  'filter5':'FOXA1', 'filter29':'HNF4G', 'filter2':'RXRA/HNF4G',\n",
    "                  'filter99':'FOXA2', 'filter92':'HNF4G', 'filter12':'FOXJ3',\n",
    "                  'filter34':'Gmeb1', 'filter16':\"HNF4G\", \"filter19\":\"HNF4G\",\n",
    "                  'filter71':'MEOX2', 'filter62':'FOXA1', 'filter27':'Gmeb1',\n",
    "                  'filter67':'FOXA1', 'filter95':'Gmeb1', 'filter13':'FOXJ3',\n",
    "                  'filter64':'Gmeb1', 'filter47':'Gmeb1', 'filter6':'FOXK1',\n",
    "                  'filter40':'NR1A4:RXRA'}\n",
    "\n",
    "#['NR3C1', 'MEF2A', 'TFAP4 (NEUROD1/TWIST1/FIGLA)', 'KLF1', 'ATF1 (FOS:JUN)']\n",
    "multi_random = {'filter18':'Gmeb1/FOS:JUN', 'filter64':'Gmeb1', 'filter14':'HES2/MYC',\n",
    "               'filter17':'FIGLA/NEUROD1', 'filter28':'FOS:JUN', 'filter79':'NEUROD1/TWIST1',\n",
    "               'filter2':'Gmeb1', 'filter76':'MITF/USF2', 'filter9':\"NEUROD1/TWIST1\",\n",
    "               'filter5':'Gmeb1', 'filter31':'Gmeb1', 'filter70':'TWIST1',\n",
    "               'filter43':'RARA:RXRG', 'filter33':'Gmeb1', 'filter29':'FOS:JUN',\n",
    "               'filter85':'GATA1:TAL1', 'filter27':'Gmeb1', 'filter7':'USF2/ZEB1',\n",
    "               'filter47':'FOS:JUN', 'filter60':'Gmeb1', 'filter12':'Myog',\n",
    "               'filter36':'Gmeb1'}\n",
    "\n",
    "indiv_random = {}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
