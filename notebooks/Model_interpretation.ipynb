{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import *\n",
    "from models import *\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from Bio.SeqUtils import GC\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONSTANTS AND HYPERPARAMETERS (add to yaml)\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = h5py.File(\"../data/tf_peaks_50_partial.h5\", 'r')\n",
    "\n",
    "x = torch.Tensor(data['train_in'])\n",
    "y = torch.Tensor(data['valid_in'])\n",
    "z = torch.Tensor(data['test_in'])\n",
    "\n",
    "x_lab = torch.Tensor(data['train_out'])\n",
    "y_lab = torch.Tensor(data['valid_out'])\n",
    "z_lab = torch.Tensor(data['test_out'])\n",
    "\n",
    "res = torch.cat((x, y, z), dim=0)\n",
    "res_lab = torch.cat((x_lab, y_lab, z_lab), dim=0)\n",
    "\n",
    "all_dataset = torch.utils.data.TensorDataset(res, res_lab)\n",
    "dataloader = torch.utils.data.DataLoader(all_dataset, \n",
    "                                                  batch_size=100, shuffle=False,\n",
    "                                                  num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_labels = list(data['target_labels'])\n",
    "\n",
    "target_labels = [i.decode(\"utf-8\") for i in target_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNetDeep(50).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"../weights_multimodel_partial/model_epoch_6_.pth\"))\n",
    "model.eval();\n",
    "\n",
    "#copy trained model weights to motif extraction model\n",
    "motif_model = motifCNN(model, 50).to(device)\n",
    "motif_model.load_state_dict(model.state_dict())\n",
    "motif_model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of PWMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run predictions with full model on all data\n",
    "running_outputs = []\n",
    "running_labels = []\n",
    "sequences = []\n",
    "sigmoid = nn.Sigmoid()\n",
    "with torch.no_grad():\n",
    "    for seq, lbl in dataloader:\n",
    "        sequences.extend(seq.numpy())\n",
    "        seq = seq.to(device)\n",
    "        out = model(seq)\n",
    "        out = sigmoid(out.detach().cpu()) #for BCEWithLogits\n",
    "        running_outputs.extend(out.numpy()) #for BCEWithLogits\n",
    "        running_labels.extend(lbl.numpy())\n",
    "\n",
    "running_labels = np.array(running_labels)\n",
    "running_outputs = np.array(running_outputs)\n",
    "sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_full_round = np.round(running_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_comp = np.equal(pred_full_round, running_labels)\n",
    "idx = np.argwhere(np.sum(arr_comp, axis=1) >= 50).squeeze() #43563"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = res[idx, :, :]\n",
    "res_lab2 = res_lab[idx, :]\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(res2, res_lab2)\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                          batch_size=100, shuffle=False,\n",
    "                                                  num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first layer activations and predictions with leave-one-filter-out\n",
    "predictions, activations = get_motifs(data_loader, motif_model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = \"../data/motifs_for_multimodel.meme\"\n",
    "\n",
    "get_memes(activations, res2, res_lab2, output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"../data/filter_importance/\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_filter_importance(model, data_loader, target_labels, len(target_labels),\n",
    "                          output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impacts = pd.read_csv(\"../data/filter_importance/average_impacts.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap of filter importance\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "                   z=impacts,\n",
    "                   x=list(impacts),\n",
    "                   y=impacts.index,\n",
    "                   hoverongaps = False\n",
    "    ))\n",
    "\n",
    "fig.update_layout(title='Filter impacts',\n",
    "                 font=dict(\n",
    "                     family=\"Courier New, monospace\",\n",
    "                     size=10,\n",
    "                     color=\"black\"\n",
    "                 ))\n",
    "\n",
    "fig.update_layout(autosize=False,width=1000,height=1000)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_classes = {}\n",
    "\n",
    "with open(\"../data/clusters.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"#\"):\n",
    "            continue\n",
    "        \n",
    "        line_parts = line.strip().split()\n",
    "        tf_class = line_parts[-1]\n",
    "        tf_name = line_parts[0]\n",
    "\n",
    "        tf_classes[tf_name.upper()] = tf_class\n",
    "    \n",
    "tf_classes = pd.Series(tf_classes)\n",
    "\n",
    "tf_classes = tf_classes.sort_values(ascending=True)\n",
    "tf_classes_df = tf_classes[list(impacts)].sort_values(ascending=True)\n",
    "impacts_sorted = impacts[tf_classes_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tomtom_results = pd.read_csv(\"../data/tomtom_multimodel.tsv\", sep=\"\\t\",comment=\"#\")\n",
    "filters_with_min_q = tomtom_results.groupby('Query_ID').min()[\"q-value\"]\n",
    "filters_with_min_q[filters_with_min_q < 0.01].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually - using tomtom.html\n",
    "filter_TFs = {\"filter10\":\"CREB1\", \"filter13\":\"JUN\",\n",
    "              \"filter14\":\"JUND\", \"filter15\":\"USF2\", \"filter17\":\"\",\n",
    "              \"filter2\":\"JUN\", \"filter23\":\"\",\n",
    "              \"filter28\":\"CTCF\", \"filter3\":\"USF2\", \"filter32\":\"\",\n",
    "              \"filter43\":\"JUN\", \"filter45\":\"FOXA1\", \"filter49\":\"CTCF\",\n",
    "              \"filter5\":\"GATA2\", \"filter50\":\"\", \"filter53\":\"\", \"filter54\":\"\",\n",
    "              \"filter58\":\"CEBPB\", \"filter59\":\"USF2\", \"filter60\":\"NR2F2\",\n",
    "              \"filter61\":\"JUND\", \"filter63\":\"\", \"filter65\":\"FOXA1\", \n",
    "              \"filter68\":\"CTCF\", \"filter70\":\"CTCF\", \"filter73\":\"JUND\",\n",
    "              \"filter74\":\"\", \"filter75\":\"JUN\", \"filter76\":\"\", \"filter78\":\"USF2\",\n",
    "              \"filter79\":\"JUN\", \"filter83\":\"\", \"filter86\":\"\",\n",
    "              \"filter87\":\"CTCF\", \"filter92\":\"NR2F1\", \"filter94\":\"MYC\",\n",
    "              \"filter95\":\"MAX\", \"filter98\":\"FOXA1\", \"filter99\":\"CTCF\"}\n",
    "\n",
    "filter_TFs = pd.Series(filter_TFs)\n",
    "\n",
    "with open('../data/multimodel_filter_TFs.pickle', 'wb') as f:\n",
    "    pickle.dump(filter_TFs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_info = pd.DataFrame({\"Q\":filters_with_min_q, \"TFs\":filter_TFs})\n",
    "filters_info = filters_info.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from Chendi Wang\n",
    "with open('../data/motifs_for_multimodel.meme') as fp:\n",
    "    line = fp.readline()\n",
    "    motifs=[]\n",
    "    motif_names=[]\n",
    "    while line:\n",
    "        #determine length of next motif\n",
    "        if line.split(\" \")[0]=='MOTIF':\n",
    "            #add motif number to separate array\n",
    "            motif_names.append(line.split(\" \")[1])\n",
    "            #get length of motif\n",
    "            line2=fp.readline().split(\" \")\n",
    "            motif_length = int(float(line2[5]))\n",
    "            #read in motif \n",
    "            current_motif=np.zeros((19, 4)) # Edited pad shorter ones with 0\n",
    "            for i in range(motif_length):\n",
    "                current_motif[i,:] = fp.readline().split(\"\\t\")\n",
    "            motifs.append(current_motif)\n",
    "        line = fp.readline()\n",
    "    motifs = np.stack(motifs)  \n",
    "    motif_names = np.stack(motif_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate IC (from Chendi Wang)\n",
    "#set background frequencies of nucleotides\n",
    "bckgrnd = [0.25, 0.25, 0.25, 0.25]\n",
    "#compute information content of each motif\n",
    "info_content = []\n",
    "position_ic = []\n",
    "epsilon = 1e-11\n",
    "for i in range(motifs.shape[0]): \n",
    "    length = motifs[i,:,:].shape[0]\n",
    "    position_wise_ic = np.subtract(np.sum(np.multiply(motifs[i,:,:],np.log2(motifs[i,:,:] + epsilon)), axis=1),np.sum(np.multiply(bckgrnd,np.log2(bckgrnd))))                                    \n",
    "    position_ic.append(position_wise_ic)\n",
    "    ic = np.sum(position_wise_ic, axis=0)\n",
    "    info_content.append(ic)\n",
    "info_content = np.stack(info_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_content = pd.Series(info_content, index=motif_names)\n",
    "filter_content = filter_content[filters_with_min_q.index]\n",
    "filters_info[\"IC\"] = filter_content\n",
    "\n",
    "filter_impact = impacts.max(axis=1)\n",
    "filter_impact = filter_impact[filters_with_min_q.index]\n",
    "filters_info[\"Impact\"] = filter_impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=filters_info[\"IC\"],\n",
    "    y=np.log10(filters_info[\"Impact\"]),\n",
    "    mode=\"markers+text\",\n",
    "    name=\"Lines, Markers and Text\",\n",
    "    text=filters_info[\"TFs\"],\n",
    "    textposition=\"top center\",\n",
    "    marker=dict(\n",
    "        size=8,\n",
    "        color=np.log10(filters_info[\"Q\"])*-1, #set color equal to a variable\n",
    "        colorscale='Bluered', # one of plotly colorscales\n",
    "        showscale=True,\n",
    "        colorbar=dict(\n",
    "            title=\"-log10(TOMTOM q.value)\",\n",
    "            titleside=\"right\",\n",
    "            titlefont=dict(size=18)\n",
    "        )\n",
    "    )\n",
    "    #marker_size=np.log10(filters_info[\"Q\"])*-2.5,\n",
    "    #marker_color=\"blue\"\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "                 font=dict(\n",
    "                     family=\"Arial\",\n",
    "                     size=12,\n",
    "                     color=\"black\"\n",
    "                 ))\n",
    "\n",
    "fig.update_layout(yaxis_title='Filter influence (log10)',\n",
    "                 xaxis_title='Information content',\n",
    "                 plot_bgcolor='rgba(0,0,0,0)', paper_bgcolor='rgba(0,0,0,0)')\n",
    "fig.update_xaxes(showline=True, linewidth=2, linecolor='black', titlefont=dict(size=18))\n",
    "fig.update_yaxes(showline=True, linewidth=2, linecolor='black', titlefont=dict(size=18))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting individual models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_name = \"HNF4A\"\n",
    "\n",
    "data = h5py.File(\"../TRAIN_DATA_INDIV_INTER/\"+TF_name +\"/h5_files/\" +\n",
    "                 TF_name + \"_tl.h5\", 'r')\n",
    "\n",
    "\n",
    "x = torch.Tensor(data['train_in'])\n",
    "y = torch.Tensor(data['valid_in'])\n",
    "z = torch.Tensor(data['test_in'])\n",
    "\n",
    "x_lab = torch.Tensor(data['train_out'])\n",
    "y_lab = torch.Tensor(data['valid_out'])\n",
    "z_lab = torch.Tensor(data['test_out'])\n",
    "\n",
    "res = torch.cat((x, y, z), dim=0)\n",
    "res_lab = torch.cat((x_lab, y_lab, z_lab), dim=0)\n",
    "\n",
    "all_dataset = torch.utils.data.TensorDataset(res, res_lab)\n",
    "dataloader = torch.utils.data.DataLoader(all_dataset, \n",
    "                                                  batch_size=100, shuffle=False,\n",
    "                                                  num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNetDeep(1).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"../MODEL_WEIGHTS_INDIV_INTER/\" + TF_name +\n",
    "                                 \"_real_indiv_weights_TL/\" + TF_name + \"_tl_weights/\" +\n",
    "                                 \"model_epoch_4_.pth\"))\n",
    "model.eval();\n",
    "\n",
    "#copy trained model weights to motif extraction model\n",
    "motif_model = motifCNN(model, 1).to(device)\n",
    "motif_model.load_state_dict(model.state_dict())\n",
    "motif_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run predictions with full model on all data\n",
    "running_outputs = []\n",
    "running_labels = []\n",
    "sequences = []\n",
    "sigmoid = nn.Sigmoid()\n",
    "with torch.no_grad():\n",
    "    for seq, lbl in dataloader:\n",
    "        sequences.extend(seq.numpy())\n",
    "        seq = seq.to(device)\n",
    "        out = model(seq)\n",
    "        out = sigmoid(out.detach().cpu()) #for BCEWithLogits\n",
    "        running_outputs.extend(out.numpy()) #for BCEWithLogits\n",
    "        running_labels.extend(lbl.numpy())\n",
    "\n",
    "running_labels = np.array(running_labels)\n",
    "running_outputs = np.array(running_outputs)\n",
    "sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_full_round = np.round(running_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_comp = np.equal(pred_full_round, running_labels)\n",
    "idx = np.argwhere(np.sum(arr_comp, axis=1) >= 1).squeeze() #160819\n",
    "idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = res[idx, :, :]\n",
    "res_lab2 = res_lab[idx, :]\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(res2, res_lab2)\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                          batch_size=100, shuffle=False,\n",
    "                                                  num_workers=2)\n",
    "\n",
    "output_folder = \"../data/filter_importance/\" + TF_name + \"/\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "    \n",
    "compute_filter_importance(model, data_loader, target_labels, len(target_labels),\n",
    "                          output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, activations = get_motifs(data_loader, motif_model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "#get_memes(activations, res2, res_lab2, output_folder + TF_name + \"_noTL.meme\")\n",
    "get_memes(activations, res2, res_lab2, output_folder + TF_name + \"_50_TL.meme\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
